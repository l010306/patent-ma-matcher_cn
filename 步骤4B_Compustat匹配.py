# -*- coding: utf-8 -*-
"""
CompustatåŒ¹é… - æ­¥éª¤4Bï¼šåº”ç”¨å®¡æ ¸ç»“æœï¼ˆä¼˜åŒ–ç‰ˆï¼‰
================================================
åŠŸèƒ½ï¼šè¯»å–äººå·¥å®¡æ ¸åçš„éªŒè¯æ–‡ä»¶ï¼Œå°†Compustat IDåˆå¹¶åˆ°final_outcome

æ”¹è¿›ç‚¹ï¼š
1. è¯¦ç»†çš„æ•°æ®éªŒè¯
2. ä¿ç•™IDçš„å‰å¯¼é›¶ï¼ˆä½¿ç”¨dtype=strï¼‰
3. è¯¦ç»†æ—¥å¿—
"""

import pandas as pd
import logging
from datetime import datetime

# ==========================================
# é…ç½®æ—¥å¿—
# ==========================================
# ç¡®ä¿logsæ–‡ä»¶å¤¹å­˜åœ¨
import os
if not os.path.exists('logs'):
    os.makedirs('logs')

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler(f'logs/compustat_merge_4B_{datetime.now().strftime("%Y%m%d_%H%M%S")}.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# ==========================================
# 1. è·¯å¾„é…ç½®
# ==========================================
PATH_MAIN = "/Users/lidachuan/Desktop/Patent Data/final_outcome_1993_1997_COMPLETE.xlsx"
PATH_COMPUSTAT = "/Users/lidachuan/Desktop/Patent Data/compustat_19802025.csv"
PATH_VERIFIED = "/Users/lidachuan/Desktop/Patent Data/company_match_verification.xlsx"
PATH_OUTPUT = "/Users/lidachuan/Desktop/Patent Data/final_outcome.xlsx"

# ==========================================
# 2. ä¸»å¤„ç†å‡½æ•°
# ==========================================

def main():
    start_time = datetime.now()
    
    logger.info("=" * 60)
    logger.info("CompustatåŒ¹é… - æ­¥éª¤4Bï¼šåº”ç”¨å®¡æ ¸ç»“æœï¼ˆä¼˜åŒ–ç‰ˆï¼‰")
    logger.info("=" * 60)
    
    # ========== æ­¥éª¤1: è¯»å–æ•°æ® ==========
    logger.info("\næ­¥éª¤ 1/4: è¯»å–æ•°æ®...")
    
    # è¯»å–ä¸»è¡¨
    logger.info("   åŠ è½½ä¸»è¡¨...")
    try:
        df_main = pd.read_excel(PATH_MAIN)
        logger.info(f"   âœ… ä¸»è¡¨åŠ è½½å®Œæˆ: {len(df_main):,} è¡Œ")
    except Exception as e:
        logger.error(f"   âŒ è¯»å–å¤±è´¥: {e}")
        return False
    
    # è¯»å–äººå·¥éªŒè¯è¡¨ï¼ˆå·²å®¡æ ¸ï¼‰
    logger.info("   åŠ è½½äººå·¥éªŒè¯è¡¨...")
    try:
        df_verify = pd.read_excel(
            PATH_VERIFIED, 
            usecols=['Acquiror_Original', 'Matched_Compustat_Original']
        )
        # å»é‡
        df_verify = df_verify.drop_duplicates(subset=['Acquiror_Original'])
        logger.info(f"   âœ… éªŒè¯è¡¨åŠ è½½å®Œæˆ: {len(df_verify):,} ä¸ªæœ‰æ•ˆåŒ¹é…å¯¹")
    except Exception as e:
        logger.error(f"   âŒ è¯»å–å¤±è´¥: {e}")
        logger.error("   è¯·ç¡®ä¿å·²å®Œæˆæ­¥éª¤4Aå¹¶äººå·¥å®¡æ ¸äº†éªŒè¯æ–‡ä»¶")
        return False
    
    # è¯»å– Compustat æ•°æ®ï¼ˆä¿ç•™å‰å¯¼é›¶ï¼‰
    logger.info("   åŠ è½½ Compustat æ•°æ®...")
    try:
        cols_to_load = ['conm', 'gvkey', 'cusip', 'cik']
        df_comp = pd.read_csv(
            PATH_COMPUSTAT, 
            usecols=cols_to_load, 
            dtype=str,  # ä¿ç•™å‰å¯¼é›¶
            low_memory=False
        )
        logger.info(f"   âœ… Compustat æ•°æ®åŠ è½½å®Œæˆ: {len(df_comp):,} è¡Œ")
    except ValueError:
        # å¦‚æœåˆ—åä¸åŒ¹é…ï¼Œå°è¯•å…¨é‡è¯»å–
        logger.warning("   åˆ—åå¯èƒ½ä¸åŒ¹é…ï¼Œå°è¯•å…¨é‡è¯»å–...")
        df_comp = pd.read_csv(PATH_COMPUSTAT, dtype=str, low_memory=False)
        logger.info(f"   âœ… Compustat æ•°æ®åŠ è½½å®Œæˆï¼ˆå…¨é‡ï¼‰: {len(df_comp):,} è¡Œ")
    except Exception as e:
        logger.error(f"   âŒ è¯»å–å¤±è´¥: {e}")
        return False
    
    # ========== æ­¥éª¤2: å¤„ç† Compustat æ•°æ® ==========
    logger.info("\næ­¥éª¤ 2/4: æ„å»º Compustat å­—å…¸...")
    
    # å»é™¤ conm ä¸ºç©ºçš„è¡Œ
    df_comp_clean = df_comp[df_comp['conm'].notna()].copy()
    
    # æŒ‰ conm å»é‡ï¼ˆä¿ç•™ç¬¬ä¸€æ¡è®°å½•ï¼‰
    df_comp_unique = df_comp_clean.drop_duplicates(subset=['conm'])
    
    logger.info(f"   âœ… Compustat å”¯ä¸€å…¬å¸: {len(df_comp_unique):,}")
    
    # ========== æ­¥éª¤3: åˆå¹¶æ•°æ® ==========
    logger.info("\næ­¥éª¤ 3/4: åˆå¹¶æ•°æ®...")
    
    # 3.1 å°†éªŒè¯è¡¨ä¸Compustat IDåˆå¹¶
    logger.info("   é˜¶æ®µ 3.1: è·å– Compustat ID...")
    df_verify_with_ids = pd.merge(
        df_verify,
        df_comp_unique[['conm', 'gvkey', 'cusip', 'cik']],
        left_on='Matched_Compustat_Original',
        right_on='conm',
        how='left'
    )
    
    # ç»Ÿè®¡åŒ¹é…æˆåŠŸç‡
    id_matched = df_verify_with_ids['gvkey'].notna().sum()
    logger.info(f"   âœ… IDåŒ¹é…æˆåŠŸ: {id_matched} / {len(df_verify)} ({id_matched/len(df_verify)*100:.1f}%)")
    
    # 3.2 ä¸ä¸»è¡¨åˆå¹¶ï¼ˆå¡«å……ç°æœ‰çš„gvkey/cusip/cikåˆ—ï¼‰
    logger.info("   é˜¶æ®µ 3.2: å¡«å……ä¸»è¡¨çš„IDåˆ—...")
    
    # åˆ›å»ºæ˜ å°„å­—å…¸
    acquiror_to_ids = {}
    for _, row in df_verify_with_ids.iterrows():
        acquiror_name = row['Acquiror_Original']
        acquiror_to_ids[acquiror_name] = {
            'gvkey': row.get('gvkey', None),
            'cusip': row.get('cusip', None),
            'cik': row.get('cik', None),
            'compustat_name': row.get('Matched_Compustat_Original', None)
        }
    
    # å¡«å……ç°æœ‰åˆ—ï¼ˆä¿ç•™åŸæœ‰å€¼ï¼Œä»…å¡«å……ç©ºå€¼ï¼‰
    df_final = df_main.copy()
    
    # ç¡®ä¿åˆ—å­˜åœ¨
    for col in ['gvkey', 'cusip', 'cik', 'compustat_name']:
        if col not in df_final.columns:
            df_final[col] = None
    
    # é€è¡Œå¡«å……
    for idx, row in df_final.iterrows():
        acquiror_name = row['acquiror_name']
        if acquiror_name in acquiror_to_ids:
            ids = acquiror_to_ids[acquiror_name]
            # åªå¡«å……ç©ºå€¼
            if pd.isna(df_final.at[idx, 'gvkey']):
                df_final.at[idx, 'gvkey'] = ids['gvkey']
            if pd.isna(df_final.at[idx, 'cusip']):
                df_final.at[idx, 'cusip'] = ids['cusip']
            if pd.isna(df_final.at[idx, 'cik']):
                df_final.at[idx, 'cik'] = ids['cik']
            if pd.isna(df_final.at[idx, 'compustat_name']):
                df_final.at[idx, 'compustat_name'] = ids['compustat_name']
    
    logger.info(f"   âœ… å¡«å……å®Œæˆï¼Œæœ€ç»ˆè¡Œæ•°: {len(df_final):,}")
    
    # ========== æ­¥éª¤4: ä¿å­˜ç»“æœ ==========
    logger.info("\næ­¥éª¤ 4/4: ä¿å­˜ç»“æœ...")
    
    try:
        df_final.to_excel(PATH_OUTPUT, index=False)
        logger.info(f"   âœ… æ–‡ä»¶å·²ä¿å­˜: {PATH_OUTPUT}")
    except Exception as e:
        logger.error(f"   âŒ ä¿å­˜å¤±è´¥: {e}")
        return False
    
    # ========== å®Œæˆæ‘˜è¦ ==========
    duration = (datetime.now() - start_time).total_seconds()
    
    # ç»Ÿè®¡
    total_rows = len(df_final)
    matched_count = df_final['compustat_name'].notna().sum()
    match_rate = matched_count / total_rows * 100
    
    has_gvkey = df_final['gvkey'].notna().sum()
    has_cusip = df_final['cusip'].notna().sum()
    has_cik = df_final['cik'].notna().sum()
    
    logger.info("\n" + "=" * 60)
    logger.info("æ­¥éª¤4B å®Œæˆï¼")
    logger.info("=" * 60)
    logger.info(f"â±  æ€»è€—æ—¶: {duration:.2f} ç§’")
    logger.info(f"\nğŸ“Š ç»“æœç»Ÿè®¡:")
    logger.info(f"   - æ€»è¡Œæ•°: {total_rows:,}")
    logger.info(f"   - åŒ¹é… Compustat: {matched_count:,} ({match_rate:.1f}%)")
    logger.info(f"   - æœ‰ gvkey: {has_gvkey:,}")
    logger.info(f"   - æœ‰ cusip: {has_cusip:,}")
    logger.info(f"   - æœ‰ cik: {has_cik:,}")
    logger.info(f"\nğŸ“ è¾“å‡ºæ–‡ä»¶:")
    logger.info(f"   {PATH_OUTPUT}")
    logger.info(f"\nâœ… å®Œæ•´æ•°æ®å¤„ç†æµç¨‹å…¨éƒ¨å®Œæˆï¼ğŸ‰")
    logger.info("=" * 60)
    
    return True


if __name__ == "__main__":
    success = main()
    exit(0 if success else 1)
