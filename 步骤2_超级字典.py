# -*- coding: utf-8 -*-
"""
è¶…çº§å­—å…¸æ„å»ºä¼˜åŒ–ç‰ˆï¼ˆæ­¥éª¤2ï¼‰
============================
åŠŸèƒ½ï¼šåˆå¹¶è‡ªåŠ¨åŒ¹é…å’Œäººå·¥å®¡æ ¸ç»“æœï¼Œæ„å»ºMaster Company Dictionary

æ”¹è¿›ç‚¹ï¼š
1. æ›´å¥½çš„é”™è¯¯å¤„ç†å’ŒéªŒè¯
2. å†²çªæ£€æµ‹å’ŒæŠ¥å‘Š
3. è¯¦ç»†çš„æ—¥å¿—è®°å½•
4. ç»Ÿè®¡ä¿¡æ¯è¾“å‡º
"""

import pandas as pd
import os
import pickle
import logging
from datetime import datetime

# ==========================================
# é…ç½®æ—¥å¿—
# ==========================================
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler(f'dict_building_{datetime.now().strftime("%Y%m%d_%H%M%S")}.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# ==========================================
# 1. é…ç½®ï¼šè¾“å…¥æ–‡ä»¶åˆ—è¡¨
# ==========================================
# å¯ä»¥åŒ…å«å¤šå¹´ä»½çš„æ–‡ä»¶ï¼ŒæŒ‰éœ€æ·»åŠ 
FILES_TO_PROCESS = [
    # --- 1993-1997å¹´æ–‡ä»¶ ---
    'Step1_Manual_Review.xlsx',      # äººå·¥å®¡æ ¸åçš„æ–‡ä»¶ï¼ˆåˆ é™¤é”™è¯¯åŒ¹é…ï¼‰
    'Step1_Auto_Results.xlsx',       # è‡ªåŠ¨åŒ¹é…ç»“æœ
    
    # --- å¦‚æœæœ‰å…¶ä»–å¹´ä»½ï¼Œæ·»åŠ åœ¨æ­¤ ---
    # '1998_2000_Manual_Review.xlsx',
    # '1998_2000_Auto_Results.xlsx',

]

# è¾“å‡ºæ–‡ä»¶é…ç½®
OUTPUT_DICT_FILE = 'Master_Company_Dictionary.pkl'       # ç”¨äºä»£ç åŠ è½½ï¼ˆPickleæ ¼å¼ï¼‰
OUTPUT_EXCEL_FILE = 'Master_Company_Dictionary_VIEW.xlsx' # ç”¨äºäººå·¥æŸ¥çœ‹ï¼ˆExcelæ ¼å¼ï¼‰

# ==========================================
# 2. ä¸»å¤„ç†å‡½æ•°
# ==========================================

def build_master_dictionary(files_list):
    """
    æ„å»ºè¶…çº§å­—å…¸
    è¿”å›: master_dict, statistics
    """
    logger.info("=" * 60)
    logger.info("å¼€å§‹æ„å»ºè¶…çº§å­—å…¸ï¼ˆMaster Company Dictionaryï¼‰")
    logger.info("=" * 60)
    
    master_dict = {}  # ç»“æ„: { 'Assignee_Original': 'Original_Acquiror_Name' }
    source_stats = []
    conflicts = []  # è®°å½•å†²çª
    
    for file_path in files_list:
        if not os.path.exists(file_path):
            logger.warning(f"âš ï¸  è·³è¿‡ï¼šæ‰¾ä¸åˆ°æ–‡ä»¶ {file_path}")
            continue
        
        logger.info(f"\næ­£åœ¨å¤„ç†: {file_path}")
        
        try:
            df = pd.read_excel(file_path)
            
            # æ£€æŸ¥å¿…è¦çš„åˆ—
            required_cols = ['Assignee_Original', 'Original_Acquiror_Name']
            if not all(col in df.columns for col in required_cols):
                logger.error(f"   âŒ é”™è¯¯ï¼šç¼ºå°‘å¿…è¦åˆ— {required_cols}ï¼Œè·³è¿‡æ­¤æ–‡ä»¶")
                continue
            
            # è¿‡æ»¤æ— æ•ˆè¡Œ
            df_valid = df.dropna(subset=required_cols)
            df_valid = df_valid[
                (df_valid['Assignee_Original'].astype(str).str.strip() != "") &
                (df_valid['Original_Acquiror_Name'].astype(str).str.strip() != "")
            ]
            
            logger.info(f"   æœ‰æ•ˆè¡Œæ•°: {len(df_valid)}")
            
            # ç»Ÿè®¡ä¿¡æ¯
            count_new = 0
            count_duplicate = 0
            count_conflict = 0
            
            for idx, row in df_valid.iterrows():
                assignee_raw = str(row['Assignee_Original']).strip()
                acquiror_std = str(row['Original_Acquiror_Name']).strip()
                
                if assignee_raw not in master_dict:
                    # æ–°æ˜ å°„
                    master_dict[assignee_raw] = acquiror_std
                    count_new += 1
                else:
                    # å·²å­˜åœ¨çš„æ˜ å°„
                    existing = master_dict[assignee_raw]
                    if existing == acquiror_std:
                        # é‡å¤ä½†ä¸€è‡´
                        count_duplicate += 1
                    else:
                        # å†²çªï¼
                        count_conflict += 1
                        conflicts.append({
                            'Assignee': assignee_raw,
                            'Existing_Acquiror': existing,
                            'New_Acquiror': acquiror_std,
                            'Source_File': file_path
                        })
                        # ç­–ç•¥ï¼šä¿ç•™ç¬¬ä¸€æ¬¡å‡ºç°çš„æ˜ å°„ï¼Œè®°å½•å†²çª
                        logger.warning(f"   âš ï¸  å†²çª: '{assignee_raw}' å·²æ˜ å°„ä¸º '{existing}'ï¼Œæ–°å€¼ '{acquiror_std}' è¢«å¿½ç•¥")
            
            logger.info(f"   âœ… å¤„ç†å®Œæˆ: æ–°å¢ {count_new}ï¼Œé‡å¤ {count_duplicate}ï¼Œå†²çª {count_conflict}")
            
            source_stats.append({
                'File': os.path.basename(file_path),
                'Valid_Rows': len(df_valid),
                'New_Mappings': count_new,
                'Duplicates': count_duplicate,
                'Conflicts': count_conflict
            })
            
        except Exception as e:
            logger.error(f"   âŒ è¯»å–å¤±è´¥: {e}")
    
    return master_dict, source_stats, conflicts


def save_dictionary(master_dict, source_stats, conflicts):
    """ä¿å­˜å­—å…¸å’Œç»Ÿè®¡ä¿¡æ¯"""
    logger.info("\n" + "=" * 60)
    logger.info("ä¿å­˜ç»“æœ")
    logger.info("=" * 60)
    
    if not master_dict:
        logger.error("âŒ é”™è¯¯ï¼šå­—å…¸ä¸ºç©ºï¼æ²¡æœ‰æå–åˆ°ä»»ä½•æ˜ å°„å…³ç³»ã€‚")
        return False
    
    # 1. ä¿å­˜ä¸º Pickleï¼ˆç”¨äºåç»­ä»£ç åŠ è½½ï¼‰
    with open(OUTPUT_DICT_FILE, 'wb') as f:
        pickle.dump(master_dict, f)
    logger.info(f"âœ… Pickleæ–‡ä»¶å·²ä¿å­˜: {OUTPUT_DICT_FILE}")
    
    # 2. ä¿å­˜ä¸º Excelï¼ˆç”¨äºäººå·¥æŸ¥çœ‹ï¼‰
    df_out = pd.DataFrame(
        list(master_dict.items()), 
        columns=['Assignee_Original_Name', 'Mapped_Acquiror_Name']
    )
    df_out = df_out.sort_values('Mapped_Acquiror_Name').reset_index(drop=True)
    df_out.to_excel(OUTPUT_EXCEL_FILE, index=False)
    logger.info(f"âœ… Excelæ–‡ä»¶å·²ä¿å­˜: {OUTPUT_EXCEL_FILE}")
    
    # 3. ä¿å­˜ç»Ÿè®¡ä¿¡æ¯
    if source_stats:
        df_stats = pd.DataFrame(source_stats)
        stats_file = 'Dictionary_Build_Statistics.xlsx'
        df_stats.to_excel(stats_file, index=False)
        logger.info(f"âœ… ç»Ÿè®¡ä¿¡æ¯å·²ä¿å­˜: {stats_file}")
    
    # 4. å¦‚æœæœ‰å†²çªï¼Œä¿å­˜å†²çªæŠ¥å‘Š
    if conflicts:
        df_conflicts = pd.DataFrame(conflicts)
        conflict_file = 'Dictionary_Conflicts.xlsx'
        df_conflicts.to_excel(conflict_file, index=False)
        logger.warning(f"âš ï¸  å†²çªæŠ¥å‘Šå·²ä¿å­˜: {conflict_file} ({len(conflicts)} æ¡å†²çª)")
    
    return True


def print_summary(master_dict, source_stats, conflicts):
    """æ‰“å°æ‘˜è¦ä¿¡æ¯"""
    logger.info("\n" + "=" * 60)
    logger.info("æ„å»ºå®Œæˆæ‘˜è¦")
    logger.info("=" * 60)
    
    logger.info(f"\nğŸ“Š æ€»ä½“ç»Ÿè®¡:")
    logger.info(f"   - æ€»æ˜ å°„å…³ç³»æ•°: {len(master_dict):,}")
    logger.info(f"   - å¤„ç†æ–‡ä»¶æ•°: {len(source_stats)}")
    logger.info(f"   - æ£€æµ‹åˆ°çš„å†²çª: {len(conflicts)}")
    
    if source_stats:
        logger.info(f"\nğŸ“ å„æ–‡ä»¶è´¡çŒ®:")
        for stat in source_stats:
            logger.info(f"   {stat['File']}")
            logger.info(f"      æ–°å¢: {stat['New_Mappings']}, é‡å¤: {stat['Duplicates']}, å†²çª: {stat['Conflicts']}")
    
    # ç»Ÿè®¡æ˜ å°„åˆ°åŒä¸€å…¬å¸çš„å˜ä½“æ•°
    from collections import Counter
    acquiror_counts = Counter(master_dict.values())
    top_companies = acquiror_counts.most_common(10)
    
    logger.info(f"\nğŸ¢ å˜ä½“æœ€å¤šçš„å…¬å¸ï¼ˆTop 10ï¼‰:")
    for company, count in top_companies:
        logger.info(f"   {company}: {count} ä¸ªå˜ä½“")
    
    if conflicts:
        logger.info(f"\nâš ï¸  è­¦å‘Š: å‘ç° {len(conflicts)} ä¸ªå†²çªï¼Œè¯·æ£€æŸ¥ Dictionary_Conflicts.xlsx")
        logger.info("   å†²çªå¤„ç†ç­–ç•¥: ä¿ç•™é¦–æ¬¡å‡ºç°çš„æ˜ å°„")


# ==========================================
# 3. ä¸»æ‰§è¡Œæµç¨‹
# ==========================================

def main():
    start_time = datetime.now()
    
    # æ„å»ºå­—å…¸
    master_dict, source_stats, conflicts = build_master_dictionary(FILES_TO_PROCESS)
    
    # ä¿å­˜ç»“æœ
    success = save_dictionary(master_dict, source_stats, conflicts)
    
    if success:
        # æ‰“å°æ‘˜è¦
        print_summary(master_dict, source_stats, conflicts)
        
        # è®¡ç®—è€—æ—¶
        duration = (datetime.now() - start_time).total_seconds()
        
        logger.info(f"\nâ±  æ€»è€—æ—¶: {duration:.2f} ç§’")
        logger.info("\n" + "=" * 60)
        logger.info("ğŸ‰ è¶…çº§å­—å…¸æ„å»ºæˆåŠŸï¼")
        logger.info("=" * 60)
        logger.info(f"\nä¸‹ä¸€æ­¥:")
        logger.info(f"   1. æ£€æŸ¥ {OUTPUT_EXCEL_FILE} ç¡®è®¤æ˜ å°„å…³ç³»")
        logger.info(f"   2. å¦‚æœ‰å†²çªï¼Œå®¡æŸ¥ Dictionary_Conflicts.xlsx")
        logger.info(f"   3. è¿è¡Œæ­¥éª¤3ï¼ˆæœ€ç»ˆèšåˆï¼‰ä½¿ç”¨æ­¤å­—å…¸")
        
        return True
    else:
        logger.error("\nâŒ å­—å…¸æ„å»ºå¤±è´¥")
        return False


if __name__ == "__main__":
    success = main()
    exit(0 if success else 1)
